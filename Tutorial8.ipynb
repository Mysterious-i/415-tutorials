{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# OpenCV High-GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## User-assisted Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The user specifies a rectangle containing the object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Graph cut segmentation is used to find the object inside the rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# global variables\n",
    "tl = (0,0)\n",
    "br = (0,0)\n",
    "bDraw = False\n",
    "done = False\n",
    "\n",
    "# Mouse callback function\n",
    "def mouseCallBackFunc(event,x,y,flags,userdata):\n",
    "    # grab references to the global variables\n",
    "    global tl,br,bDraw,done\n",
    "    \n",
    "    # if left button is pressed\n",
    "    if ( event == cv2.EVENT_LBUTTONDOWN ):\n",
    "        # top-left corner\n",
    "        tl = (x,y)    \n",
    "        # set the draw flag\n",
    "        bDraw = True\n",
    "        \n",
    "    # mouse movement on the window\n",
    "    elif ( event == cv2.EVENT_MOUSEMOVE ):\n",
    "        if(bDraw):\n",
    "            # current bottom-right corner\n",
    "            br = (x,y)\n",
    "            # Display current rect\n",
    "            img_disp = img.copy()\n",
    "            cv2.rectangle(img_disp,tl,br,(0,255,0),2)\n",
    "            cv2.imshow(windowName, img_disp);\n",
    "            cv2.waitKey(10)\n",
    "            \n",
    "    # if left button is released\n",
    "    elif( event == cv2.EVENT_LBUTTONUP ):\n",
    "        # final bottom-right corner\n",
    "        br = (x,y)        \n",
    "        # Display the rect\n",
    "        img_disp = img.copy()\n",
    "        cv2.rectangle(img_disp,tl,br,(255,0,0),2)\n",
    "        cv2.imshow(windowName, img_disp);\n",
    "        cv2.waitKey(1000)        \n",
    "        # Set the flag\n",
    "        done = True\n",
    "\n",
    "\n",
    "# Load the image\n",
    "SAMPLES_DATA_DIR = 'C:/opencv/sources/samples/data/'\n",
    "img = cv2.imread(SAMPLES_DATA_DIR+'left.jpg')\n",
    "#img = cv2.imread('cheeky_penguin.png')\n",
    "img_disp = img.copy()\n",
    "\n",
    "# Create a window\n",
    "windowName = \"Draw a rectange over the object\"\n",
    "cv2.namedWindow(windowName);\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(windowName, img);\n",
    "\n",
    "# Set the callback function for any mouse event\n",
    "cv2.setMouseCallback(windowName,mouseCallBackFunc,None);\n",
    "\n",
    "# Prompt the user to draw a rectange over the object\n",
    "while(1):\n",
    "    cv2.waitKey(1)\n",
    "    if (done):\n",
    "        break\n",
    "        \n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Segmentation using graph cuts\n",
    "# cv2.grabCut(img,mask,rect,bgdModel,fgdModel,iterCount,mode)\n",
    "# img - Input image\n",
    "# mask - It is a mask image where we specify which areas are background, foreground or probable background/foreground\n",
    "#      - It is done by the following flags, cv2.GC_BGD, cv2.GC_FGD, cv2.GC_PR_BGD, cv2.GC_PR_FGD\n",
    "# rect - It is the coordinates of a rectangle which includes the foreground object in the format (x,y,w,h)\n",
    "# bdgModel,fgdModel - These are arrays used by the algorithm internally. Use two np.float64 type zero arrays of size (1,65)\n",
    "# iterCount - Number of iterations the algorithm should run\n",
    "# mode - It should be cv2.GC_INIT_WITH_RECT for initializing with a rect, or cv2.GC_INIT_WITH_MASK for initializing with a mask\n",
    "rect = (tl[0],tl[1],br[0]-tl[0],br[1]-tl[1])\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "mask, bgdModel, fgdModel = cv2.grabCut(img,None,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# If a pixel is BGD or probably BGD, set it to 0, otherwise, set it to 1\n",
    "mask = np.where((mask==cv2.GC_BGD)|(mask==cv2.GC_PR_BGD),0,1).astype('uint8')\n",
    "# newaxis is used to increase the dimension of the existing array by one more dimension\n",
    "img_disp = img * mask[:,:,np.newaxis]\n",
    "\n",
    "# Display result\n",
    "cv2.imshow(\"Result\", img_disp);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Drawing a flow arrow on points with a magnitude flow > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Video reader\n",
    "SAMPLES_DATA_DIR = 'C:/opencv/sources/samples/data/'\n",
    "videoreader = cv2.VideoCapture(SAMPLES_DATA_DIR+\"vtest.avi\")\n",
    "\n",
    "# Flow magnitude threshold \n",
    "MAG_THRESH = 0.99\n",
    "\n",
    "# trackbar callback function\n",
    "def trackbarCallback(x):\n",
    "    # grab references to the global variables\n",
    "    global MAG_THRESH\n",
    "    # read the current positions of the trackbars\n",
    "    MAG_THRESH = cv2.getTrackbarPos('MagThresh(%)',windowName) / 100\n",
    "    \n",
    "# Create a window\n",
    "windowName = \"Optical Flow\"\n",
    "cv2.namedWindow(windowName);\n",
    "\n",
    "# Add a trackbar to the window\n",
    "# The callback function is called when the trackbar changes\n",
    "cv2.createTrackbar('MagThresh(%)',windowName,1,100,trackbarCallback) \n",
    "\n",
    "# Set trackbar initial position\n",
    "cv2.setTrackbarPos('MagThresh(%)',windowName,int(MAG_THRESH*100))\n",
    "\n",
    "\n",
    "# Read a single frame (the first frame)\n",
    "# read() also returns a bool (True/False). If frame is read correctly, it will be True\n",
    "ret, currentframeRGB = videoreader.read()\n",
    "# convert to grayscale\n",
    "currentframe = cv2.cvtColor(currentframeRGB,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "while(1):\n",
    "    # Update the previous frame to the current frame\n",
    "    previousFrameRGB = currentframeRGB.copy()\n",
    "    previousFrame = currentframe.copy()\n",
    "   \n",
    "    # Read the next frame\n",
    "    ret, currentframeRGB = videoreader.read()\n",
    "    # terminates the loop if the last frame is reached\n",
    "    if ret==0:\n",
    "        break\n",
    "    # convert to grayscale\n",
    "    currentframe = cv2.cvtColor(currentframeRGB,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute optical flow using the Gunner Farnebackâ€™s algorithm\n",
    "    # calcOpticalFlowFarneback(prev,next,pyr_scale,levels,winsize,iterations,poly_n,poly_sigma,flags)\n",
    "    # pyr_scale: parameter specifying the image scale (<1) to build pyramids\n",
    "    # levels: number of pyramid layers including the initial image\n",
    "    # winsize: averaging window size\n",
    "    # iterations: number of iterations the algorithm does at each pyramid level\n",
    "    # poly_n: size of the pixel neighborhood used to find polynomial expansion in each pixel\n",
    "    # poly_sigma: standard deviation of the Gaussian that is used to smooth derivatives\n",
    "    # flags: OPTFLOW_USE_INITIAL_FLOW uses the input flow as an initial flow approximation\n",
    "    # flow has the same size as prev with two channels: horizontal (0) and vertical (1) flow components\n",
    "    flow = cv2.calcOpticalFlowFarneback(previousFrame,currentframe, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Compute the mag/ang flow from the horizontal/vertical flow\n",
    "    mag = np.sqrt( flow[:,:,0]*flow[:,:,0] + flow[:,:,1]*flow[:,:,1] )\n",
    "    \n",
    "    # Normalize the mag flow\n",
    "    magMax = np.amax(mag)\n",
    "    # avoid dividing by 0\n",
    "    mag = mag / (magMax+np.finfo(float).eps)        \n",
    "    \n",
    "    # list of all points, higher than the threshold\n",
    "    # loc[0] is an numpy array, containing the x coordinates\n",
    "    # loc[1] is an numpy array, containing the y coordinates\n",
    "    loc = np.where( mag >= MAG_THRESH)\n",
    "    \n",
    "    # loop through the points\n",
    "    # zip() aggregates elements from loc[0] and loc[1]\n",
    "    for pt in zip(*loc[::-1]):  \n",
    "        # draw arrows\n",
    "        flowX = flow[pt[1],pt[0],0] \n",
    "        flowY = flow[pt[1],pt[0],1] \n",
    "        pt2 = ( int(pt[0]+flowX) , int(pt[1]+flowY) )\n",
    "        cv2.arrowedLine(previousFrameRGB,pt,pt2,(255,0,0),1,cv2.LINE_AA,0,0.7)\n",
    "    \n",
    "    \n",
    "    # Display    \n",
    "    cv2.imshow(windowName,previousFrameRGB)\n",
    "    # Wait\n",
    "    k = cv2.waitKey(500) & 0xff\n",
    "    # Terminate on pressing the 'escape' key \n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Destroy the video reader    \n",
    "videoreader.release()\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
