{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's create a class to stitch two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Stitcher:\n",
    "    # the __init__ function is automatically called upon instantiation\n",
    "    # is't a good practice to initialize/reset all class members here\n",
    "    def __init__(self):               \n",
    "        # create a SIFT object\n",
    "        self.sift = cv2.xfeatures2d.SIFT_create()\n",
    "        # create a Brute-Force Matcher\n",
    "        self.bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "      \n",
    "    def featureExtraction(self):        \n",
    "        self.kp1,self.desc1 = self.sift.detectAndCompute(self.img1,None)\n",
    "        self.kp2,self.desc2 = self.sift.detectAndCompute(self.img2,None)\n",
    "        \n",
    "    def matchDescriptors(self):\n",
    "        self.matches = self.bf.match(self.desc1,self.desc2)\n",
    "        \n",
    "    def displayMatches(self, N):\n",
    "        # Sort them in the order of their distance\n",
    "        matches = sorted(self.matches, key = lambda x:x.distance)        \n",
    "        # Draw the best N matches\n",
    "        img = cv2.drawMatches(self.img1,self.kp1,self.img2,self.kp2,matches[:N],None,flags=2)\n",
    "        cv2.imshow(\"Matched keypoints\",img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def homography(self):\n",
    "        # We need to convert the matched points (cv.DMatch) into Nx2 Numpy arrays\n",
    "        # A cv2.DMatch object contains distance, queryIdx and trainIdx\n",
    "        # distance: The Euclidean distance between the the descriptors from the two sets\n",
    "        # queryIdx: The index of the matched descriptor in the query set (1st set)\n",
    "        # trainIdx:: The index of the matched descriptor in the train set (2nd set)\n",
    "        \n",
    "        # local placeholders for the matched points coordinates\n",
    "        srcPts =  np.empty((len(self.matches),2))\n",
    "        dstPts =  np.empty((len(self.matches),2))\n",
    "        for i in range(len(self.matches)):\n",
    "            srcPts[i,:] = np.float32(self.kp1[self.matches[i].queryIdx].pt)\n",
    "            dstPts[i,:] = np.float32(self.kp2[self.matches[i].trainIdx].pt)\n",
    "        \n",
    "        # compute the 3x3 transformation matrix to map dstPts into srcPts (note the ordering)\n",
    "        self.M, mask = cv2.findHomography(dstPts, srcPts, cv2.RANSAC,5.0)\n",
    "        \n",
    "    def findOutputLimits(self):\n",
    "        # we need to find the projected image corners to determine the size of the panorama image\n",
    "        # the projected corners might map to negative pixel coordinates -> translate the image\n",
    "        \n",
    "        # the four corners are [0,0], [0,height-1], [width-1,0] and [width-1,height-1]\n",
    "        # [x_proj y_proj 1] = M * [x_corner y_corner 1]\n",
    "        \n",
    "        # top left\n",
    "        tl = np.dot(self.M, np.array([0,0,1]))\n",
    "        tl = tl/tl[-1]           \n",
    "        # top right\n",
    "        tr = np.dot(self.M, np.array([self.img2.shape[1]-1,0,1]))\n",
    "        tr = tr/tr[-1]        \n",
    "        # bottom left\n",
    "        bl = np.dot(self.M, np.array([0, self.img2.shape[0]-1,1]))\n",
    "        bl = bl/bl[-1]        \n",
    "        # bottom right\n",
    "        br = np.dot(self.M, np.array([self.img2.shape[1]-1, self.img2.shape[0]-1,1]))\n",
    "        br = br/br[-1]\n",
    "        \n",
    "        # find the xMin and yMin\n",
    "        self.xMin = min(tl[0],tr[0],bl[0],br[0],0)\n",
    "        self.xMax = max(tl[0],tr[0],bl[0],br[0],self.img1.shape[1])\n",
    "        self.yMin = min(tl[1],tr[1],bl[1],br[1],0)\n",
    "        self.yMax = max(tl[1],tr[1],bl[1],br[1],self.img1.shape[0])\n",
    "\n",
    "        # create a 3x3 translation matrix\n",
    "        # [ [1 0 -xMin], [0 1 -yMin], [0 0 1] ]\n",
    "        self.T = np.array([[1,0,-self.xMin],[0,1,-self.yMin],[0,0,1]])        \n",
    "        \n",
    "        # apply the translation matrix to the transformation matrix\n",
    "        #  M <- T * M      \n",
    "        self.M = np.dot(self.T,self.M)        \n",
    "\n",
    "        # compute the panorama size        \n",
    "        self.panoSize = (int(self.xMax-self.xMin+1),int(self.yMax-self.yMin+1))                  \n",
    "        \n",
    "    def perspectiveWarp(self):\n",
    "        # warp the second image into the panorama\n",
    "        self.pano = cv2.warpPerspective(self.img2, self.M, self.panoSize)\n",
    "        # no blending, just copy the left-side image into the panorama\n",
    "        self.pano[-self.yMin:self.img1.shape[0]-self.yMin,-self.xMin:self.img1.shape[1]-self.xMin] = self.img1             \n",
    "        \n",
    "    def doStitch(self,image1,image2):\n",
    "        # make a deep copy of the input images\n",
    "        self.img1 = image1.copy()\n",
    "        self.img2 = image2.copy() \n",
    "        # compute keypoints/descriptors\n",
    "        self.featureExtraction()        \n",
    "        # match descriptors\n",
    "        self.matchDescriptors()\n",
    "        # compute the transformation matrix\n",
    "        self.homography()\n",
    "        # translate the images and compute the panorama size\n",
    "        self.findOutputLimits() \n",
    "        # apply a perspective warp to stitch the images\n",
    "        self.perspectiveWarp()                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can create an object of the Stitcher class, pass the images to it to compute the panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image \n",
    "img1 = cv2.imread('1.png')\n",
    "img2 = cv2.imread('2.png')\n",
    "\n",
    "# Stitcher object\n",
    "s = Stitcher()\n",
    "# feed the images to the main method \n",
    "s.doStitch(img1,img2)\n",
    "\n",
    "# display the results\n",
    "cv2.imshow(\"Pano\", s.pano)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
